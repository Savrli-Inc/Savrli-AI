---
# **Savrli AI Chat Endpoint**
---

A stateless FastAPI microservice that exposes an `/ai/chat` endpoint to generate conversational recommendations using OpenAIâ€™s GPT-3.5-Turbo model.
Itâ€™s designed for use with the **Savrli app**, deployed on **Vercel** at:

> ğŸŒ **Base URL:** Your endpoint

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ api
â”‚   â””â”€â”€ index.py
â”œâ”€â”€ postman
â”‚   â””â”€â”€ Savrli-AI-Chat.postman_collection.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ vercel.json
```

**Description:**

* `api/index.py` â€” Main FastAPI app file exposing `/ai/chat` and `/` routes.
* `postman/Savrli-AI-Chat.postman_collection.json` â€” Postman collection for testing.
* `requirements.txt` â€” Python dependencies.
* `vercel.json` â€” Vercel deployment configuration.

---

## âš™ï¸ Overview

This API takes a userâ€™s text prompt and returns a contextual, conversational response generated via OpenAIâ€™s GPT-3.5-Turbo.
No session or conversation memory is stored â€” each request is processed independently.

### **Endpoint**

`POST /ai/chat`

### **Request Body (JSON)**

```json
{
  "prompt": "User's text prompt"
}
```

* **prompt** *(required)* â€” The text input from the user.
* Must be non-empty (trimmed).
* Max length: ~4000 characters (per OpenAI limit).

### **Response Body (JSON)**

```json
{
  "response": "AI's generated reply"
}
```

---

## ğŸ“¡ API Details

| **Status Code** | **Meaning**             | **When It Occurs**                              |
| --------------- | ----------------------- | ----------------------------------------------- |
| 200             | âœ… Success               | Valid prompt processed; AI reply returned.      |
| 400             | âš ï¸ Bad Request          | Empty or missing `prompt`.                      |
| 500             | âŒ Internal Server Error | OpenAI API failure, rate limit, or invalid key. |

---

## ğŸ§ª Testing with cURL

Use the **staging URL**:

```bash
curl -X POST https://{base-url}/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Recommend a quick breakfast recipe"}'
```

Example successful response:

```json
{
  "response": "How about scrambled eggs with avocado toast and a side of orange juice?"
}
```

---



### 5. **Test Api**

```bash
curl -X POST BASE_URL/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Suggest a productivity hack"}'
```

---

## ğŸš€ Deployment (Vercel)

### **vercel.json**

```json
{
  "builds": [
    { "src": "api/index.py", "use": "@vercel/python" }
  ],
  "routes": [
    { "src": "/(.*)", "dest": "api/index.py" }
  ]
}
```

### Steps:

1. Push your project to GitHub.
2. Link your repo to Vercel.
3. Add your environment variable:

   ```
   OPENAI_API_KEY = your-openai-api-key
   ```
4. Deploy â€” it will be live 

---

